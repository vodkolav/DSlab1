{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b860ea-7339-4679-847d-8366c0c0930b",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vodkolav/DSlab1/blob/Colab/DSlab2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad2eea-f696-4c32-a74b-1f87122416e7",
   "metadata": {},
   "source": [
    "# Homework 2 submission\n",
    "for course: Data Science lab 2   \n",
    "by  Michael Berger   \n",
    " \n",
    "\n",
    "Lecturer: Dr. Sharon Yalov-Handzel  \n",
    "Afeka College of engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6f791-f22a-4360-b84d-63272b403162",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"DEBUG\"\n",
    "#context = \"RELEASE\"\n",
    "\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive',)\n",
    "  pfx = \"/content/drive/MyDrive/Studies/M.Sc/DSlab2\"\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  pfx = \"\"\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db92a4-f744-43c4-b873-c520257c644c",
   "metadata": {},
   "source": [
    "## 1. Use the dataset from UCI Machine Learning Repository:\n",
    "\"Individual household electric power consumption\" for performing time series analysis.  \n",
    "https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44808d2-08db-4999-abe2-e107a3b2ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ucimlrepo\n",
    "! pip install scikit-learn==1.4.2\n",
    "! pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec037f7b-2808-4018-9c1d-b7f768b03733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, clone_model\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, LSTM, Dense, Attention, Concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import statistics as stat\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo , dotdict\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b75cd72-1929-4cc5-864f-4ee4cdbca16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = datetime.now().strftime(\"%Y.%m.%d_%H-%M-%S\")\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3e86d7-a529-493f-b19c-c77d44af5a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plotly plots appear on github preview\n",
    "#pio.renderers.default = \"notebook_connected\"\n",
    "#pio.renderers.default = \"notebook+pdf\"\n",
    "#pio.renderers.default = \"sphinx_gallery\"\n",
    "#pio.renderers.default = \"plotly_mimetype+jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1853b-d849-4b46-8361-76253172dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965fd631-603e-4dc4-9ef9-a2d2cb7caefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = r\"data/individual_household_electric_power_consumption.pkl\"\n",
    "pth = Path(pfx) / Path(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6430207-7aa1-4a3a-b7cd-ec9f3110a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pth.exists():\n",
    "    with open(pth, \"rb\") as fl:\n",
    "        individual_household_electric_power_consumption = pickle.load(fl)\n",
    "else: \n",
    "    \n",
    "    individual_household_electric_power_consumption = fetch_ucirepo(id=235) \n",
    "    pth.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(pth, \"wb\") as fl:\n",
    "        pickle.dump(individual_household_electric_power_consumption, fl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7c384-1f4e-491b-a60a-2dfe7df7ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data (as pandas dataframes) \n",
    "X = individual_household_electric_power_consumption.data.features \n",
    "y = individual_household_electric_power_consumption.data.targets \n",
    "  \n",
    "# variable information \n",
    "print(individual_household_electric_power_consumption.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea673f-25f9-480b-b615-7f7bbee22c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# metadata \n",
    "meta = json.dumps(individual_household_electric_power_consumption.metadata,indent=2)\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dfe336-b287-4e8b-a4fc-c25246c60802",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadic = individual_household_electric_power_consumption.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e555a5-759e-4e27-a6ab-642258057b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mylen(o):\n",
    "    if type(o)==int:\n",
    "        return str(o)\n",
    "    if type(o)==type(None):\n",
    "        return \"0\"\n",
    "    else:\n",
    "        return len(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5f0d1-56ac-4ab3-8845-6f1004c5ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showkeys(dic, ind = 0):\n",
    "    if type(dic)== dotdict:\n",
    "        for k,v  in dic.items() :\n",
    "            print(\" \"*ind , k, \"|\", type(v).__name__, \",\", mylen(v) )\n",
    "            showkeys(dic[k], ind+4)\n",
    "\n",
    "showkeys(metadic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924dbbc0-ae1d-40c0-b84d-e5f845ceb250",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadic[\"abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f6b12-f575-4607-bb64-560a4265c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadic[\"additional_info\"][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300eaa71-c36a-4230-ab88-8537d843868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadic[\"additional_info\"][\"variable_info\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ef774-ba78-4db0-8417-ae3d91ac53d7",
   "metadata": {},
   "source": [
    "## 2. Perform Exploratory Data Analysis (EDA) of the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051fb47b-9a91-439a-a13b-9cc4ffdfc6f6",
   "metadata": {},
   "source": [
    "First, convert all values to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42da093-4419-4644-bddf-2099b52a3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "numcols = ['Global_active_power', 'Global_reactive_power',\n",
    "           'Voltage', 'Global_intensity', 'Sub_metering_1', \n",
    "           'Sub_metering_2', 'Sub_metering_3']\n",
    "\n",
    "for c in numcols:\n",
    "    X[c] = pd.to_numeric(X[c], errors = \"coerce\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb294ea-ae1e-42a4-98cb-44ab3bd0eecf",
   "metadata": {},
   "source": [
    "combine date and time into single col datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede3ab6-d34f-4e9d-83f5-d6dda65d98e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = X[\"Date\"] + \" \" + X[\"Time\"]\n",
    "X[\"datetime\"] = pd.to_datetime(dt, dayfirst=True)\n",
    "X = X.set_index('datetime').drop([\"Date\",\"Time\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0805f9-6afc-482e-b486-4ade1dbb0044",
   "metadata": {},
   "source": [
    "### a.  Visualize time series trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1e80a-1029-47f6-a9af-34315e1e59e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(df):\n",
    "    nonnans = df.shape[0] - df.isna().sum()\n",
    "    nonnansPrc = (nonnans / df.shape[0] * 100).apply(\"{0:.2f}%\".format)\n",
    "    sam = df.sample(1, random_state=42).squeeze()\n",
    "    res = pd.DataFrame([sam.index, df.dtypes.astype(str), nonnans,\n",
    "                        nonnansPrc, df.nunique(), sam]).transpose()\n",
    "    res.columns = [\"Column\", \"data type\", \"non-null values\", \n",
    "                   \"non-null values %\", \"unique values\", \"example\"]\n",
    "    res.sort_values(\"unique values\",ascending=False, inplace=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bfa96-291f-4291-8bb7-454f3018539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568a9ea-65ff-4435-98b4-c326c4bd793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "d = X.describe()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5e0f7-8074-4f87-8308-f3ecca4c95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d95d2d8-861c-41e3-a7b9-61bb35496241",
   "metadata": {},
   "source": [
    "### b. Check for seasonality and cyclical patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109fb36-1ff0-4c1f-8427-e8fdb658a49f",
   "metadata": {},
   "source": [
    "- Analyze distribution of power consumption\n",
    "- Identify and handle missing values or outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c01aede-f01d-4364-8778-10b51d1699cf",
   "metadata": {},
   "source": [
    "## 3. Implement a linear regression model to predict power consumption for the last three time periods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10e893-cf91-4d46-abe1-87a492e9ab5d",
   "metadata": {},
   "source": [
    "extract a smaller set Xs for debugging  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a111d3-e3a9-4015-b188-0404e093c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup original dataset as data to re-process later\n",
    "data = X.copy(deep=True)\n",
    "\n",
    "\n",
    "# debug and development values: take small chunk of data,\n",
    "# few epochs and verbose output\n",
    "if context == \"DEBUG\":\n",
    "  n_sampls = 10000\n",
    "  X = X.iloc[0:n_sampls,:]\n",
    "  time_step = 12\n",
    "  epochs = 2\n",
    "  batch_size = 64\n",
    "  verbose = 1\n",
    "else:\n",
    "  print(\"running RELEASE config. Grab a drink an a snack, it's gonna take long.\")    \n",
    "  time_step = 12\n",
    "  epochs = 15\n",
    "  batch_size = 1024\n",
    "  verbose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854af5a2-4c7b-45ea-b1ec-4fd7b96a5552",
   "metadata": {},
   "source": [
    "### b. Prepare features (consider lag variables, time-based features) \n",
    "features: \n",
    "year\n",
    "month \n",
    "week\n",
    "day\n",
    "hour\n",
    "every variable + 10 of it's lags \n",
    "\n",
    "y's: \n",
    "Global_active_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21fbcdb-10bb-4b7b-8847-e76db333c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the data to fill the NaN values\n",
    "#   Xs  or X\n",
    "df= X[\"Global_active_power\"].resample(\"1min\").mean().ffill().to_frame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ef93a-10e0-4f00-98e0-1785b9b3ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "tmp = scaler.fit_transform(df)\n",
    "df[\"Global_active_power\"] = tmp\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d30532-b58b-4f0d-b591-3a86408e328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,time_step):\n",
    "    lag = i\n",
    "    df[f\"Global_active_power.L{lag}\"] = df[\"Global_active_power\"].shift(lag)\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc87e395-1006-42f8-b6fd-fd33b288e2b6",
   "metadata": {},
   "source": [
    "### a. Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c83350b-838a-423c-af52-5e85052717c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find appropriate train/test ratio for the data\n",
    "td = df.index.max() - df.index.min()\n",
    "td.days * 24 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5757b243-fc8b-4042-8d0d-762883dc0476",
   "metadata": {},
   "outputs": [],
   "source": [
    "td.days / 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5298544-ea96-4164-b9ac-45c785223e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd9efe-f6cb-4cd9-9db0-7d13275afd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "1- (3 * 30 * 24 * 60 ) / X.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f16e6-8889-4157-9d98-d8f6f7011068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into feature and target\n",
    "target = \"Global_active_power\"\n",
    "t = df[target]\n",
    "P = df.drop(columns= target)                                             \n",
    "#Split the data into train and test sets\n",
    "cutoff = int(len(P) * 0.94) # size of train\n",
    "X_train, y_train = P[:cutoff], t[:cutoff]\n",
    "X_test, y_test = P[cutoff:], t[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc21a25b-e704-409b-944b-89da360e495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30fe52-a204-4e1f-842c-a9969bf73204",
   "metadata": {},
   "source": [
    "### c. Train the model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c046b5-6f21-4acb-9bec-c988de994bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = LinearRegression()\n",
    "res = LR_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ed7ff-5cf2-404c-8ca1-5f33f5b769e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = pd.DataFrame(\n",
    "             {\n",
    "             \"y_test\": y_test,\n",
    "             \"LinearRegression\": LR_model.predict(X_test).squeeze()\n",
    "             })\n",
    "df_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd93e1-4602-4493-a5ed-74c3ef57eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_preds(df):\n",
    "    # compare predictions of different models \n",
    "    # over a small (for performance) chunk of data \n",
    "    df_pred_test = df[:10000]\n",
    "\n",
    "    bkp = Path(pfx) / Path(\"backup\") / Path(run_id)\n",
    "    bkp.mkdir(parents=True, exist_ok=True)\n",
    "    df_pred_test.to_json(bkp / Path(\"test_preds.json\"), indent=4)\n",
    "    \n",
    "    fig = px.line(df_pred_test, labels= {\"value\": \"Powah!\"}, \n",
    "              title = \"Actual powah vs. Predicted powah.\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14220ac9-9f68-4681-b705-c6f6dc5e791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_preds(df_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907046b-f90a-47ba-87cc-c697b266b3c9",
   "metadata": {},
   "source": [
    "## 4. Evaluate the linear regression model using appropriate metrics:\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- R-squared (RÂ²) value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22742783-99b8-44b4-a74b-e159862f79ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = pd.DataFrame(columns=['model','data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356c52d-9bb0-4f6f-ac30-9726eeff8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqiz(y):\n",
    "    # required to deal with higher dimensional outputs \n",
    "    if len(y.shape)>2 and y.shape[2]>1:\n",
    "        y = y[:,0,0]\n",
    "    return y.squeeze()\n",
    "\n",
    "\n",
    "def pipeline(model, x_train, y_train, x_test, y_test, model_args={}):\n",
    "    \n",
    "    margs = model_args.copy() # there is no pass-by-value in python, duh    \n",
    "    # Train the model\n",
    "    print(f\"training model, please wait...\")\n",
    "    model.fit(x_train, y_train, **margs) # , epochs=epochs, validation_split= .1, verbose=0)\n",
    "    \n",
    "    if len(model_args.values())>0:\n",
    "        margs.pop(\"epochs\")\n",
    "        margs.pop(\"verbose\")\n",
    "\n",
    "    print(f\"evaluating model, please wait...\")\n",
    "    y_trn_pred = model.predict(x_train, **margs)    \n",
    "    y_pred = model.predict(x_test, **margs)\n",
    "\n",
    "    #TODO: Invert predictions back to original values range?\n",
    "    # train_predict = scaler.inverse_transform(train_predict)\n",
    "    # Y = scaler.inverse_transform([Y])\n",
    "    \n",
    "    #df_pred_test = pd.DataFrame({\"y_test\": y_test,\"y_pred\": y_pred})\n",
    "   \n",
    "    res = {}\n",
    "    print(\"1) y_train.shape: \", y_train.shape,\"| y_trn_pred.shape: \", y_trn_pred.shape)\n",
    "    # Evaluate the model on train set\n",
    "    y_train = sqiz(y_train)\n",
    "    y_trn_pred = sqiz(y_trn_pred)\n",
    "    print(\"2) y_train.shape: \", y_train.shape,\"| y_trn_pred.shape: \", y_trn_pred.shape)\n",
    "    \n",
    "    # note: [] on rhs are required for converting to df later on\n",
    "    res[\"trn_MAE\"] = [mean_absolute_error(y_train, y_trn_pred)]\n",
    "    res[\"trn_MSE\"] = [mean_squared_error(y_train, y_trn_pred)]\n",
    "    res[\"trn_RMSE\"] = [root_mean_squared_error(y_train, y_trn_pred)]\n",
    "    res[\"trn_Rsq\"] = [r2_score(y_train, y_trn_pred)]\n",
    "\n",
    "    print(\"1) y_test.shape: \", y_test.shape,\"| y_pred.shape: \", y_pred.shape)\n",
    "    # Evaluate the model on test set\n",
    "    y_test = sqiz(y_test)\n",
    "    y_pred = sqiz(y_pred)\n",
    "    print(\"2) y_test.shape: \", y_test.shape,\"| y_pred.shape: \", y_pred.shape)\n",
    "    \n",
    "    res[\"tst_MAE\"] = [mean_absolute_error(y_test, y_pred)]\n",
    "    res[\"tst_MSE\"] = [mean_squared_error(y_test, y_pred)]\n",
    "    res[\"tst_RMSE\"] = [root_mean_squared_error(y_test, y_pred)]\n",
    "    res[\"tst_Rsq\"] = [r2_score(y_test, y_pred)]\n",
    "    print(\"done\")\n",
    "    return model, res\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6784d94-ea8a-4e08-ba15-01319b92caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def report(result, model_label, data_label):\n",
    "    a = result\n",
    "    a[\"model\"] = model_label\n",
    "    a[\"data\"] = data_label\n",
    "    log_df = pd.DataFrame(a)    \n",
    "    global experiments \n",
    "\n",
    "    row = experiments.query(f\"model=='{model_label}' and data == '{data_label}'\")    \n",
    "    if(experiments.shape[0]>0) and len(row) > 0:\n",
    "        import warnings\n",
    "        warnings.warn(f\"experiment data  for model label '{model_label}' \\n\\\n",
    "        and data label '{data_label}' already exist. replacing.\")        \n",
    "        experiments.drop(row.index, inplace=True)\n",
    "        #experiments[[\"model\",\"data\"]].head()\n",
    "        #drop(fit_runs, 'data', label)\n",
    "    \n",
    "    experiments = pd.concat([experiments, log_df])\n",
    "    experiments.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    bkp = Path(pfx) / Path(\"backup\") / Path(run_id)\n",
    "    bkp.mkdir(parents=True, exist_ok=True)\n",
    "    experiments.to_json(bkp / Path(\"experiments.json\"), indent=4)\n",
    "   \n",
    "    #print(experiments.head())\n",
    "\n",
    "    metrics = list(result.keys())\n",
    "    metrics.sort()\n",
    "    \n",
    "    log_df_melted = experiments.melt(id_vars=['model','data'], \n",
    "                            value_vars= metrics, #['accuracy', 'loss'], \n",
    "                            var_name='metric', \n",
    "                            value_name='value')\n",
    "    \n",
    "    rx = r\"(?P<set>[trns]+_)?(?P<metric>[\\dA-Za-z-]+)\"\n",
    "    nspl = log_df_melted.metric.str.extract(rx)\n",
    "    log_df_melted.drop('metric',axis=1, inplace=True)\n",
    "    log_df_melted = log_df_melted.join(nspl)    \n",
    "    log_df_melted.loc[log_df_melted.set == \"trn_\", \"set\"] = \"trn\"\n",
    "    #log_df_melted.loc[log_df_melted.set == \"val_\", \"set\"] = \"val\"\n",
    "    log_df_melted.loc[log_df_melted.set == \"tst_\", \"set\"] = \"tst\"\n",
    "\n",
    "    log_df_melted = log_df_melted.query(\"metric!='Rsq'\")  \n",
    "\n",
    "\n",
    "    #vertical bars\n",
    "    # dims = {'x':'data', \n",
    "    #         'y':'value', \n",
    "    #         'facet_row':'metric',\n",
    "    #         'facet_col':'model',   \n",
    "    #         'color':'set'}\n",
    "\n",
    "    #horizontal bars\n",
    "    dims = {'x':'value', \n",
    "            'y':'data', \n",
    "            'facet_row':'model',\n",
    "            'facet_col':'metric',   \n",
    "            'color':'set'}\n",
    "\n",
    "    ttl = \"table cols: metrics| cell x axis: value of given metric for given dataset and model  <br>\" + \\\n",
    "          \"table rows: models | cell y axis: different processings of the dataset | colors: training or testing set<br>\"\n",
    "    \n",
    "    fig = px.bar(log_df_melted, title= ttl,\n",
    "                 barmode = 'group', text_auto='.2',\n",
    "                 category_orders={\"set\": [\"trn\",\"val\",\"tst\"]},\n",
    "                 **dims )\n",
    "   \n",
    "    #fig.update_yaxes(matches=None,)\n",
    "    # Update layout\n",
    "    fig.update_layout(height=800, width=1000)\n",
    "    fig.update_traces(textfont_size=14, textangle=0, textposition=\"outside\", cliponaxis=True)\n",
    "\n",
    "    #fig.update_yaxes(matches='y domain')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd1692-c8a0-4086-9645-dcebe83d4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = DummyRegressor(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef49b38-6151-4e84-978a-130e7a7952f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model, res = pipeline(baseline_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "report(res, \"Baseline\", \"basic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d9bd6-0070-448b-843e-58d4435755d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test[\"baseline\"] =  baseline_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc05f2-1b4f-4f87-881b-99342b42f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae0ab5-e259-4107-8b96-7647ab6c1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, res = pipeline(model, X_train, y_train, X_test, y_test)\n",
    "report(res, \"LinearRegression\", \"basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76d556-5d32-4730-bc93-80060c2cca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_preds(df_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34325d-3272-4506-926c-6f7e92ac75ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd2d998-a266-4e6b-85ef-36e20af2a031",
   "metadata": {},
   "source": [
    "## 5. Recurrent Neural Network (RNN)\n",
    "Implement a Recurrent Neural Network (RNN) for power consumption prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ca933-d7a7-4abd-8354-c3ea7f961cef",
   "metadata": {},
   "source": [
    "### a. Preprocess data for RNN input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e51393-3774-4665-b346-5012df3fc5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a8b54-ac3b-4269-b8cc-6455c56b273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into feature and target\n",
    "target = \"Global_active_power\"\n",
    "t = df[target]\n",
    "P = df.drop(columns= target)                     \n",
    "\n",
    "\n",
    "#Split the data into train and test sets\n",
    "X_train, y_train = P[:cutoff], t[:cutoff]\n",
    "X_test, y_test = P[cutoff:], t[cutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49243cfd-46df-4439-afdf-a4e159c61e19",
   "metadata": {},
   "source": [
    "### b. Design and train the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5557d-b6df-4aa6-bfed-9f5f627ad0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence_length = X_train.shape[1]\n",
    "\n",
    "# Build an RNN model\n",
    "Rnn_model = Sequential([\n",
    "    Input((time_step, 1)),\n",
    "    SimpleRNN(units=32, activation='relu'),\n",
    "    Dense(units=1)\n",
    "])\n",
    "\n",
    "Rnn_model.compile(optimizer='adam', loss='mse')\n",
    "model_args = {\"epochs\":epochs, \"batch_size\":batch_size, \"verbose\": verbose}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846e39a-4759-423f-b79f-e68489e82df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rnn_model, res = pipeline(Rnn_model, X_train, y_train, X_test, y_test, model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b3d8e-b886-41d9-806e-95880672f581",
   "metadata": {},
   "source": [
    "### c. Make predictions and visualize results  \n",
    "\n",
    " TODO: visualise the time series with predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da3fb52-f2b1-44db-8506-d741a7ea642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test[\"RNN\"] =  Rnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85fbf9-eff3-49de-806b-3169c7fbf50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_preds(df_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13203337-f487-4c91-b2a6-87da8e47255e",
   "metadata": {},
   "source": [
    "### d. Compare performance metrics with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64de299-8234-4da0-b7f6-fba471230109",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(res, \"RNN\", \"basic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c09030-5cd8-41b3-bd90-ad9279d2a098",
   "metadata": {},
   "source": [
    "## 6. Long Short-Term Memory (LSTM)\n",
    "Implement Long Short-Term Memory (LSTM) for power consumption prediction:\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a73ccf-b9f2-4d50-a06a-8ed54e7efcaf",
   "metadata": {},
   "source": [
    "### a. Preprocess data for LSTM input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d32cccf-b584-45eb-bde9-44632b57174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into feature and target\n",
    "target = \"Global_active_power\"\n",
    "t = df[[target]]\n",
    "P = df.drop(columns= target)                     \n",
    "\n",
    "#Split the data into train and test sets\n",
    "X_train, y_train = P[:cutoff], t[:cutoff]\n",
    "X_test, y_test = P[cutoff:], t[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca724362-9c23-4b41-927e-293ef48c39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2c51c-f70e-43e5-81a4-78f6b9487e34",
   "metadata": {},
   "source": [
    "### b. Design and train the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dcfebb-9e36-4f19-842d-ec465eaea651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the LSTM network\n",
    "LSTM_model = Sequential()\n",
    "LSTM_model.add(Input((time_step, 1)))\n",
    "LSTM_model.add(LSTM(50, return_sequences=True ))\n",
    "LSTM_model.add(LSTM(50, return_sequences=False))\n",
    "LSTM_model.add(Dense(1))\n",
    "\n",
    "LSTM_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model_args = {\"epochs\":epochs, \"batch_size\":batch_size, \"verbose\":verbose}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea431f9-efba-45dd-af21-61a020413610",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(LSTM_model ,\n",
    "    show_shapes=True,\n",
    "    #show_dtype=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=200,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf22424-0318-4580-868e-c7c894668936",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd1c67-721a-49b9-a0da-b7d62616aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57f23d-1b0d-42c0-b813-b5ea3d81f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model, res = pipeline(LSTM_model, X_train, y_train, X_test, y_test, model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a159ee-f715-4848-ac21-8da93f223a99",
   "metadata": {},
   "source": [
    "### c. Make predictions and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da927eb-5a8a-4e6f-ab0e-97ae1debcb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test[\"LSTM\"] =  LSTM_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe25830-aae8-411a-a65f-a0f02ca6cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_preds(df_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cd8c9-92ac-4093-9d65-10427ac0a668",
   "metadata": {},
   "source": [
    "### d. Compare performance metrics with previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687701f6-772d-4e0f-b4a7-82c9f760c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(res, \"LSTM\", \"basic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934ef0b5-9df5-477b-8921-e430bef53aff",
   "metadata": {},
   "source": [
    "## 7. LSTM with Attention\n",
    "Implement an LSTM model with an Attention layer for power consumption prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ef113-f8e1-4cc7-a28e-8b92a4afef33",
   "metadata": {},
   "source": [
    "### a. Design and train the LSTM model with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6b409-4d57-495f-bc60-f8ec74e122cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing context length, goes to decoder\n",
    "d = 4\n",
    "# the rest is historical  context, goes to encoder\n",
    "\n",
    "t    = df.iloc[:,0:d]\n",
    "Xdec = df.iloc[:,1:(d+1)]\n",
    "Xenc = df.iloc[:,(d+1):]\n",
    "\n",
    "[Xenc.shape, Xdec.shape], t.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de7405-e884-4523-9d39-f5a33ab94bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test sets\n",
    "X_train, y_train = [Xenc[:cutoff], Xdec[:cutoff]], t[:cutoff]\n",
    "X_test , y_test  = [Xenc[cutoff:], Xdec[cutoff:]], t[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984521ee-aba8-4812-bee9-5672c068f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train[0].shape, X_train[1].shape], y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f60d7-420b-467f-b579-462c3355cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention-based Encoder-Decoder model\n",
    "\n",
    "encoder_input = Input(shape=(Xenc.shape[1], 1), name= \"encoder_input\")\n",
    "encoder_lstm = LSTM(32, return_sequences=True, name=\"encoder_lstm\")(encoder_input)\n",
    "\n",
    "decoder_input = Input(shape=(Xdec.shape[1], 1), name= \"decoder_input\")\n",
    "decoder_lstm = LSTM(32, return_sequences=True, name=\"decoder_lstm\")(decoder_input)\n",
    "\n",
    "attention = Attention(name = \"attention\")([decoder_lstm, encoder_lstm])\n",
    "combined = Concatenate(axis=-1)([decoder_lstm, attention])\n",
    "\n",
    "output = Dense(1)(combined)\n",
    "\n",
    "attention_model = Model(inputs=[encoder_input, decoder_input], outputs=output)\n",
    "attention_model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74e9b6-5181-4c89-be7d-50e4396677f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_model(attention_model,\n",
    "    show_shapes=True,\n",
    "    #show_dtype=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=200,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41934315-ef2c-458a-859f-f718abee280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model, res = pipeline(attention_model,\n",
    "                                X_train, y_train, \n",
    "                                X_test, y_test, \n",
    "                                model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0c36e-dbab-4990-aeed-713fa5454b24",
   "metadata": {},
   "source": [
    "### b. Make predictions and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ff06c-0b2d-409a-90a0-a9458e670879",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_pred =  attention_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256da7e9-e06f-4a0a-ab47-3d44acdbff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test[\"ATTN\"] = att_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f302600-f049-4a9f-b876-e8f9905ea8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_preds(df_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ca9bf-672a-40a2-b965-85f99b0c8331",
   "metadata": {},
   "source": [
    "### c. Compare performance metrics with previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7037f6-bb79-4ff7-88d5-ebe5ad943675",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(res, \"ATTN\", \"basic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d4a2aa-6383-4757-a22d-8a5c319c2007",
   "metadata": {},
   "source": [
    "### d. Analyze the Attention weights to interpret model focus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f47f9c-2de2-4c8b-abf4-3d1542ef48cc",
   "metadata": {},
   "source": [
    "## 9. Data reduction experiment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca944bd-8a5f-4906-ab99-968bcbbc57df",
   "metadata": {},
   "source": [
    "### a. Remove up to 10% of the data randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975336ce-0594-498a-ab1a-f64f45afea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_n = int(len(df) * 0.10)\n",
    "print(f\"will remove {remove_n} rows\")\n",
    "drop_indices = np.random.choice(df.index, remove_n, replace=False)\n",
    "dfm = df.drop(drop_indices)\n",
    "\n",
    "cutoff = int(len(dfm) * 0.9) # size of train\n",
    "dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d249e4f-1e49-4e82-9524-acb5ab940b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into feature and target\n",
    "target = \"Global_active_power\"\n",
    "t = dfm[target]\n",
    "P = dfm.drop(columns= target)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e319a2aa-e74e-4b2d-bbe3-202538263203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FOR lstm+Attn\n",
    "# initializing context length, goes to decoder\n",
    "d = 4\n",
    "# the rest is historical  context, goes to encoder\n",
    "\n",
    "tdec = dfm.iloc[:,0:d]\n",
    "Xdec = dfm.iloc[:,1:(d+1)]\n",
    "Xenc = dfm.iloc[:,(d+1):]\n",
    "\n",
    "[Xenc.shape, Xdec.shape], t.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3f250-bbc4-474c-9827-9f8a3e46b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test sets\n",
    "X_train, y_train = P[:cutoff], t[:cutoff]\n",
    "X_test, y_test = P[cutoff:], t[cutoff:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672f1b7-0346-4128-92a9-43591ac0eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a4fba-a9ac-4520-9010-f12ab7bacbb2",
   "metadata": {},
   "source": [
    "### b. Retrain and evaluate all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf4c94-7879-46e2-92d9-59ea00bc61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_model = DummyRegressor(strategy='mean')\n",
    "baseline_model, baseline_res = pipeline(baseline_model, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416786e9-9c02-4f87-a1a1-f251f4436e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LR_model = LinearRegression()\n",
    "LR_model, LR_res = pipeline(LR_model, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdddd0ec-7de9-4d11-a32c-922a0c0a0d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing around\n",
    "model_args = {\"epochs\":epochs, \"batch_size\":256, \"verbose\":verbose}\n",
    "# margs = model_args.copy()\n",
    "# model_args.pop(\"batch_size\")\n",
    "\n",
    "# print(asd)\n",
    "print(model_args)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceaf437-d275-4f47-9ff6-18d7fb479d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Rnn_model = clone_model(Rnn_model)\n",
    "Rnn_model.compile(optimizer='adam', loss='mse')\n",
    "Rnn_model, Rnn_res = pipeline(Rnn_model, X_train, y_train, X_test, y_test, model_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe827db-06fe-4b90-9882-620c44906c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LSTM_model = clone_model(LSTM_model)\n",
    "LSTM_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "LSTM_model, LSTM_res = pipeline(LSTM_model, X_train, y_train, X_test, y_test, model_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b3c74-6616-46c3-9b27-d15c3da676da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test sets\n",
    "X_train, y_train = [Xenc[:cutoff], Xdec[:cutoff]], tdec[:cutoff]\n",
    "X_test , y_test  = [Xenc[cutoff:], Xdec[cutoff:]], tdec[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3e03f-d5a2-43cb-8df2-7dc98fa86e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attention_model = clone_model(attention_model)\n",
    "attention_model.compile(optimizer='adam', loss='mse')\n",
    "attention_model, attn_res = pipeline(attention_model, \n",
    "                                X_train, y_train, \n",
    "                                X_test, y_test, model_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b4e78d-a77f-47d4-924f-6a3d0bf4136d",
   "metadata": {},
   "source": [
    "### c. Compare how data reduction affects each model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5c3a2-f03b-40b8-99a5-e0b7a8c70a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(baseline_res, \"Baseline\", \"reduction\")\n",
    "report(LR_res, \"LinearRegression\", \"reduction\")\n",
    "report(Rnn_res, \"RNN\", \"reduction\")\n",
    "report(LSTM_res, \"LSTM\", \"reduction\")\n",
    "report(attn_res, \"ATTN\", \"reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d9b50-ab4b-4f22-8f44-9c858fd35941",
   "metadata": {},
   "source": [
    "## 10. Data resolution experiment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613fbacf-f88b-4aaf-8eaf-e0b98c63bcb1",
   "metadata": {},
   "source": [
    "### a. Reduce the time resolution of the data by 50% (e.g., from minute-level to 2-minute intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107d6af-d284-41b2-8f1a-4bdc91916ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "taake = range(0, len(df), 2)\n",
    "dfm = df.iloc[taake]\n",
    "cutoff = int(len(dfm) * 0.9) # size of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243775b6-0e1b-47f1-a628-a21c4fe11763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into feature and target\n",
    "target = \"Global_active_power\"\n",
    "t = dfm[target]\n",
    "P = dfm.drop(columns= target)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea03d8-45af-4bea-ab72-ca03cfde2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FOR lstm+Attn\n",
    "# initializing context length, goes to decoder\n",
    "d = 4\n",
    "# the rest is historical  context, goes to encoder\n",
    "\n",
    "tdec = dfm.iloc[:,0:d]\n",
    "Xdec = dfm.iloc[:,1:(d+1)]\n",
    "Xenc = dfm.iloc[:,(d+1):]\n",
    "\n",
    "[Xenc.shape, Xdec.shape], t.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099c83a-9238-4650-99d6-0a69d4104a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into feature and target\n",
    "target = \"Global_active_power\"\n",
    "t = dfm[target]\n",
    "P = dfm.drop(columns= target)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62463332-b409-4c3d-b0b7-f88e896b3551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test sets\n",
    "X_train, y_train = P[:cutoff], t[:cutoff]\n",
    "X_test, y_test = P[cutoff:], t[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b43f3a-71a7-4833-a512-5c514f382b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5d206-84d4-43ad-90ee-cab6bd875a69",
   "metadata": {},
   "source": [
    "### b. Retrain and evaluate all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19cc2c0-fb3b-4ba2-b0c3-b5ec71b1887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_model = DummyRegressor(strategy='mean')\n",
    "baseline_model, baseline_res = pipeline(baseline_model, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e57e7b-165c-413b-9c8e-70cc7b7425c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LR_model = LinearRegression()\n",
    "LR_model, LR_res = pipeline(LR_model, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2233a6-20d6-4fb1-b343-219f106fb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Rnn_model = clone_model(Rnn_model)\n",
    "Rnn_model.compile(optimizer='adam', loss='mse')\n",
    "Rnn_model, Rnn_res = pipeline(Rnn_model, X_train, y_train, X_test, y_test, model_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543cad5-5c23-4489-b0f6-b21fc63e67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LSTM_model = clone_model(LSTM_model)\n",
    "LSTM_model.compile(optimizer='adam', loss='mse')\n",
    "LSTM_model, LSTM_res = pipeline(LSTM_model, X_train, y_train, X_test, y_test, model_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc3ef9-5242-4785-bebe-a3cb3372888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test sets\n",
    "X_train, y_train = [Xenc[:cutoff], Xdec[:cutoff]], tdec[:cutoff]\n",
    "X_test , y_test  = [Xenc[cutoff:], Xdec[cutoff:]], tdec[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee20af-1754-4e74-a811-b65c4f139bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attention_model = clone_model(attention_model)\n",
    "attention_model.compile(optimizer='adam', loss='mse')\n",
    "attention_model, attn_res = pipeline(attention_model, \n",
    "                                X_train, y_train, \n",
    "                                X_test, y_test, model_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02954d23-0969-438c-9654-84b73df4411c",
   "metadata": {},
   "source": [
    "### c. Analyze how changes in data resolution impact each model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb77359d-eae3-4bfc-9a78-bd3b72d174cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(baseline_res, \"Baseline\", \"resolution\")\n",
    "report(LR_res, \"LinearRegression\", \"resolution\")\n",
    "report(Rnn_res, \"RNN\", \"resolution\")\n",
    "report(LSTM_res, \"LSTM\", \"resolution\")\n",
    "report(attn_res, \"ATTN\", \"resolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ab34c-de3f-4c1b-afb3-665c3d09beec",
   "metadata": {},
   "source": [
    "## 8. Data augmentation experiment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe7e3f8-6a4f-4159-9324-6b4730b426d8",
   "metadata": {},
   "source": [
    "### a. Modify up to 10% of the dataset to potentially improve prediction results\n",
    "I did not understand how I should modify the dataset to improve results, so I just added another variable to the mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df1a78-1a98-4bda-a8d7-737f6ef02deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X, colname,  time_step = 12):\n",
    "    df = X[colname].resample(\"1min\").mean().ffill().to_frame()\n",
    "    # Normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    tmp = scaler.fit_transform(df)\n",
    "    df[colname] = tmp   \n",
    "    \n",
    "    for lag in range(1,time_step):\n",
    "        df[f\"{colname}.L{lag}\"] = df[colname].shift(lag)\n",
    "    \n",
    "    df.dropna(inplace = True)\n",
    "    return df\n",
    "\n",
    "gap = preprocess(X, \"Global_active_power\")\n",
    "grp = preprocess(X, \"Global_reactive_power\")\n",
    "df = gap.join(grp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19fdc58-f0ce-409c-ac7c-8d3a7e384abb",
   "metadata": {},
   "source": [
    "### b. Retrain and evaluate all three models (RNN, LSTM, LSTM with Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff87c7f-ea95-44fe-9095-969fcd12f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into feature and target\n",
    "target = \"Global_active_power\"\n",
    "t = df[target]\n",
    "P = df.drop(columns= target)\n",
    "\n",
    "#Split the data into train and test sets\n",
    "X_train, y_train = P[:cutoff], t[:cutoff]\n",
    "X_test, y_test = P[cutoff:], t[cutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e74e400-a14c-49f1-965f-76aea5947adf",
   "metadata": {},
   "source": [
    "#### Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6833c9c7-5f5b-41d5-8279-c642edad8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_model = DummyRegressor(strategy='mean')\n",
    "baseline_model, baseline_res = pipeline(baseline_model, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a3227-8513-494a-af04-7d41b4467f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LR_model = LinearRegression()\n",
    "LR_model, LR_res = pipeline(LR_model, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f7b2ce-2181-407f-9415-c5a6b2c6477a",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8eee37-9cd5-4545-81cf-d86a08b6a83d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sequence_length = X_train.shape[1]\n",
    "\n",
    "# Build an RNN model\n",
    "Rnn_model = Sequential([\n",
    "    Input((X_train.shape[1], 1)),\n",
    "    SimpleRNN(units=32, activation='relu'),\n",
    "    Dense(units=1)\n",
    "])\n",
    "\n",
    "Rnn_model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d256ba8-11b1-418b-8c3e-46d988b0ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\"epochs\":epochs, \"batch_size\":batch_size, \"verbose\": verbose}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f481f-e2c2-44c4-84ca-409f5689ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rnn_model, RNN_res = pipeline(Rnn_model, X_train, y_train, X_test, y_test, model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25549627-50cc-49ee-9776-1ad0a16a4513",
   "metadata": {},
   "source": [
    "#### LSTM  \n",
    "Requires slightly different preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3a4ab-db36-4ced-a6ef-998f1f742140",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = np.expand_dims(gap.values, axis=2)\n",
    "grp = np.expand_dims(grp.values, axis=2) \n",
    "arr = np.concatenate([gap, grp], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b25485-e8f6-4122-bbb9-fdcfe616d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into feature and target\n",
    "t = arr[:,0,:]\n",
    "P = arr[:,1:,:]\n",
    "#Split the data into train and test sets\n",
    "X_train, y_train = P[:cutoff], t[:cutoff]\n",
    "X_test, y_test = P[cutoff:], t[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e329a-1d59-42f8-b29a-a13f2955bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335249e-ce53-41cd-9490-f0f127f19481",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1:3]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591d7e1-057b-4a95-a622-a913bce82941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the LSTM network\n",
    "LSTM_model = Sequential()\n",
    "LSTM_model.add(Input(input_dim))\n",
    "LSTM_model.add(LSTM(50, return_sequences=True ))\n",
    "LSTM_model.add(LSTM(50, return_sequences=False))\n",
    "LSTM_model.add(Dense(input_dim[1]))\n",
    "\n",
    "LSTM_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model_args = {\"epochs\":epochs, \"batch_size\":32, \"verbose\":verbose}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be46b8-348d-4208-8d5a-566b32b2d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model, LSTM_res = pipeline(LSTM_model, X_train, y_train, X_test, y_test, model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01edba22-84c4-4fcd-b258-e4bd958a2cdc",
   "metadata": {},
   "source": [
    "#### LSTM with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146b965-6517-4714-8e54-aa9615e03e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial context length, goes to decoder\n",
    "d = 4\n",
    "# the rest is historical  context, goes to encoder\n",
    "\n",
    "t    = arr[:,0:d]\n",
    "Xdec = arr[:,1:(d+1)]\n",
    "Xenc = arr[:,(d+1):]\n",
    "\n",
    "t.shape, Xdec.shape, Xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55f8ba-af47-4e67-82cb-10304cc4222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Split the data into train and test sets\n",
    "\n",
    "X_train, y_train = [Xenc[:cutoff], Xdec[:cutoff]], t[:cutoff]\n",
    "X_test , y_test  = [Xenc[cutoff:], Xdec[cutoff:]], t[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a118ea-f7a6-45d5-93a8-37940f6fc657",
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train[0].shape, X_train[1].shape], y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecef7b7-2eae-4175-a970-2606b01927a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_test[0].shape, X_test[1].shape], y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44950d3-0f72-409f-b304-6c233f511b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention-based Encoder-Decoder model\n",
    "\n",
    "encoder_input = Input(shape=Xenc.shape[1:3], name= \"encoder_input\")\n",
    "encoder_lstm = LSTM(32, return_sequences=True, name=\"encoder_lstm\")(encoder_input)\n",
    "\n",
    "decoder_input = Input(shape=Xdec.shape[1:3], name= \"decoder_input\")\n",
    "decoder_lstm = LSTM(32, return_sequences=True, name=\"decoder_lstm\")(decoder_input)\n",
    "\n",
    "attention = Attention(name = \"attention\")([decoder_lstm, encoder_lstm])\n",
    "combined = Concatenate(axis=-1)([decoder_lstm, attention])\n",
    "\n",
    "output = Dense(Xenc.shape[2])(combined)\n",
    "\n",
    "attention_model = Model(inputs=[encoder_input, decoder_input], outputs=output)\n",
    "attention_model.compile(optimizer='adam', loss='mse')\n",
    "#, metrics= <keras.metrics.>[mean_squared_error, \n",
    "# RootMeanSquaredError, mean_absolute_error, R2Score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e5352f-8e83-4494-a971-9400613fb824",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(attention_model ,\n",
    "    show_shapes=True,\n",
    "    #show_dtype=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=200,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f28b1-6dd8-4015-8f19-109734b5d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model, attention_res = pipeline(attention_model,\n",
    "                                X_train, y_train, \n",
    "                                X_test, y_test, \n",
    "                                model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe1f5c-71de-4a00-88d9-cf1c0d790393",
   "metadata": {},
   "source": [
    "### c. Compare the impact of data changes on each model's performance\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d3e6b-a04c-4491-8015-048b433ba4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(baseline_res, \"Baseline\", \"augmented\")\n",
    "report(LR_res, \"LinearRegression\", \"augmented\")\n",
    "report(RNN_res,  \"RNN\",  \"augmented\")\n",
    "report(LSTM_res, \"LSTM\", \"augmented\")\n",
    "report(attention_res, \"ATTN\", \"augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e5205-831b-48ce-a840-2496161c83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"run\", run_id, \"complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dc300c-d417-4ca2-b632-e761c5b7c97c",
   "metadata": {},
   "source": [
    "## 11. Conclusion and insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13163d53-2196-4066-9a24-d2163e2100aa",
   "metadata": {},
   "source": [
    "- Summarize findings from all experiments\n",
    "- Discuss which model performed best under different conditions\n",
    "- Provide insights on the dataset's characteristics and their impact on model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a99ce6-53a4-4709-b72c-87174e2a98dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DS]",
   "language": "python",
   "name": "conda-env-DS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
